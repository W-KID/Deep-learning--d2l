{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "torch.Size([12])\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(12)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "torch.Size([3, 4])\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "x1=torch.reshape(x,(3,4))\n",
    "#或者由-1自动计算它的维度\n",
    "# x1=torch.reshape(x,(-1,4))\n",
    "# x1=torch.reshape(x,(3,-1))\n",
    "print(x1)\n",
    "print(x1.shape)\n",
    "print(x1.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "x_Zeros=torch.zeros((3,4,2))#维度是逐级递减的\n",
    "print(x_Zeros)\n",
    "x_Ones=torch.ones((3,4,2))\n",
    "print(x_Ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1471, -0.0353, -0.4368, -1.4100],\n",
       "        [ 0.9692,  0.7871,  0.4251,  0.5762],\n",
       "        [ 0.7350, -0.6314,  0.5914,  3.6466]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#随机创建符合高斯分布的数组\n",
    "x_g=torch.randn((3,4))\n",
    "x_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 2, 3, 4],\n",
      "        [3, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "#将python的列表转化为张量\n",
    "li=[[1,2,3,4],[2,2,3,4],[3,2,3,4]]\n",
    "x_li=torch.tensor(li)\n",
    "print(x_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 4., 5., 6.])\n",
      "tensor([-1.,  0.,  1.,  2.])\n",
      "tensor([2., 4., 6., 8.])\n",
      "tensor([0.5000, 1.0000, 1.5000, 2.0000])\n",
      "tensor([ 1.,  4.,  9., 16.])\n",
      "tensor([1., 0., 1., 0.])\n",
      "tensor([ 2.7183,  7.3891, 20.0855, 54.5981])\n"
     ]
    }
   ],
   "source": [
    "#tensor的数值运算\n",
    "x2=torch.tensor([1.0,2,3.0,4])\n",
    "y2=torch.tensor([2,2,2,2])\n",
    "print(x2+y2)\n",
    "print(x2-y2)\n",
    "\n",
    "print(x2*y2)\n",
    "print(x2/y2)\n",
    "\n",
    "print(x2**y2)\n",
    "print(x2%y2)\n",
    "#因为张量其中有一个是浮点数所以它的所有值都是浮点数\n",
    "\n",
    "print(torch.exp(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [ 1.,  1.,  1.,  1.],\n",
      "        [ 2.,  2.,  2.,  2.],\n",
      "        [ 3.,  3.,  3.,  3.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.,  1.,  1.,  1.,  1.],\n",
      "        [ 4.,  5.,  6.,  7.,  2.,  2.,  2.,  2.],\n",
      "        [ 8.,  9., 10., 11.,  3.,  3.,  3.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "x3 = torch.arange(12,dtype=torch.float32).reshape(3, 4)\n",
    "y3=torch.tensor([[1.0,1,1,1],[2.0,2,2,2 ],[3.0,3,3,3]])\n",
    "print(torch.cat((x3,y3),dim=0))\n",
    "print(torch.cat((x3,y3),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#逻辑运算\n",
    "print(x3==y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]]) tensor([[0, 1]])\n",
      "tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]])\n"
     ]
    }
   ],
   "source": [
    "# 广播机制 处理形状不同的两个张量之间的操作\n",
    "# 1、通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状；\n",
    "# 2、对生成的数组执行按元素操作。\n",
    "\n",
    "x4=torch.arange(3).reshape(3,1)\n",
    "y4=torch.arange(2).reshape(1,2)\n",
    "print(x4,y4)\n",
    "\n",
    "print(x4+y4)\n",
    "#x4扩展了列（复制的第一列）跟y4有相同的列\n",
    "#y4扩展了行（复制的第一行）跟x4有相同的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([ 8,  9, 10, 11])\n",
      "tensor(9)\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [88, 88, 88, 88]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [88, 99, 88, 88]])\n",
      "tensor([[ 0, 33,  2,  3],\n",
      "        [ 4, 33,  6,  7],\n",
      "        [88, 99, 88, 88]])\n"
     ]
    }
   ],
   "source": [
    "x5=torch.arange(12).reshape(3,4)\n",
    "print(x5)\n",
    "print(x5[2])\n",
    "print(x5[2,1])\n",
    "x5[2]=88\n",
    "print(x5)\n",
    "x5[2,1]=99\n",
    "print(x5)\n",
    "x5[0:2,1]=33\n",
    "print(x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#节省内存\n",
    "#x=x+y会开辟一个新的内存空间，从而x不在以前x的内存空间,可以用id来看他们的内存地址是否一样\n",
    "before=id(x4)\n",
    "x4=x4+y4\n",
    "now=id(x4)\n",
    "print(now==before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(z) 4729566720\n",
      "id(z) 4729566720\n"
     ]
    }
   ],
   "source": [
    "#解决方法1  使用切片表示法将操作的结果分配给先前分配的数组\n",
    "z=torch.zeros_like(x4)\n",
    "print(\"id(z)\",id(z))\n",
    "z[:]=x4+y4\n",
    "print(\"id(z)\",id(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 解决方法2 使用X[:] = X + Y或X += Y来减少操作的内存开销\n",
    "before1 = id(x4)\n",
    "x4[:]=x4+y4\n",
    "now1=id(x4)\n",
    "print(now1==before1)\n",
    "\n",
    "before2 = id(x4)\n",
    "x4+=y4\n",
    "now2=id(x4)\n",
    "print(now2==before2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# 张量转换为NumPy张量（ndarray)\n",
    "x5=x4.numpy()\n",
    "y5=torch.Tensor(x5)\n",
    "print(type(x5),type(y5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.2000]), 3.200000047683716, 3.200000047683716, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将大小为1的张量转换为python的标量\n",
    "x6=torch.tensor([3.2])\n",
    "print(x6,x6.item(),float(x6),int(x6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
